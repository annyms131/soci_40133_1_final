{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 715
    },
    "colab_type": "code",
    "id": "J7ZjfEqkXhD1",
    "outputId": "1ac597fe-2651-4523-d334-e34a5ed0c949"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/a0/32e3a4501ef480f7ea01aac329a716132f32f7911ef1c2fac228acc57ca7/transformers-2.6.0-py3-none-any.whl (540kB)\n",
      "\u001b[K     |████████████████████████████████| 542kB 2.5MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 12.0MB/s \n",
      "\u001b[?25hCollecting tokenizers==0.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7MB 19.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.27)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
      "\u001b[K     |████████████████████████████████| 870kB 28.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.27 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.27)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->transformers) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->transformers) (2.8.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=d457ac57dbbca9b0ae54a6fe07b820945ab5f818af574b3a7aec617aaecdd83b\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.6.0\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nm8tlyvnPV9K",
    "outputId": "cf10b723-7d3b-40ce-da5a-5bfdf09fdb86"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import AdamW, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KjVyxxH7Pqhc"
   },
   "source": [
    "*pre-processing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "C6UhXDEnT9op",
    "outputId": "5a9666ce-0321-4641-de21-0efac1fb7f61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "1T2tjRpzUaQV",
    "outputId": "8c0f6fc5-f966-4b9c-e3da-fe6e8765db33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ajkZyhJ9UjQw"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import AdamW, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "Enk-1K-FUl0y",
    "outputId": "20504306-5933-4260-ca6d-8db84be826f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=800f89ece212a482126c9e34f2918dc2f0e4a37c8fdddb537175c8132f06fb17\n",
      "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "Jq9fb34l04Fn",
    "outputId": "d8be760c-3b3b-49a5-ff2c-abfe1202c9bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "colab_type": "code",
    "id": "Duh-dCnSUqA7",
    "outputId": "41cbb6bf-58e1-4c32-838b-63c5e7da0820"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-90622458-ce1a-4ced-8126-1feeb06c3377\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-90622458-ce1a-4ced-8126-1feeb06c3377\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving df8010_train.tsv to df8010_train.tsv\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "import os\n",
    "\n",
    "# The URL for the dataset zip file.\n",
    "#url = 'https://github.com/yjnkwn/Content-Analysis-2020/blob/master/week_8/data/hw8_train.tsv'\n",
    "\n",
    "# Download the file (if we haven't already)\n",
    "#if not os.path.exists('./hw8_train.tsv'):\n",
    "#    wget.download(url, './hw8_train.tsv')\n",
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k-zVruU6NfrR"
   },
   "source": [
    "Put your data into the format BERT expects.\n",
    "\n",
    "\n",
    "*   Column 1: An ID for the row (can be just a count, or even just the same number or letter for every row, if you don’t care to keep track of each individual example).\n",
    "\n",
    "*   Column 2: A label for the row as an int. These are the classification labels that your classifier aims to predict.\n",
    "\n",
    "*   Column 3: A column of all the same letter — this is a throw-away column that you need to include because the BERT model expects it.\n",
    "\n",
    "*   Column 4: The text examples you want to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "colab_type": "code",
    "id": "WSpm5fy_XZfr",
    "outputId": "fa8fac8f-547e-40e3-de45-3a28851ce6c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 1,200\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_source</th>\n",
       "      <th>label</th>\n",
       "      <th>label_notes</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>3964428</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>Male and female juvenile rats were individuall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>2675244</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>The available data on the association between ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>3168891</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>This article analyses the practice of what is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>7467670</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>The high degree of interindividual variability...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>3834353</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>Using ethnicity of surname, nativity, resident...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>3068425</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>Well school-age children (N = 73) who had expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>2637716</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>This article is published as a tribute to Prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>28535751</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>BACKGROUND: Modifiable health-related behaviou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>21215767</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>The sheep offers a unique mammalian model in w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>2614331</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>STUDY OBJECTIVE: The aim of the study was to i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_source  ...                                           sentence\n",
       "502           3964428  ...  Male and female juvenile rats were individuall...\n",
       "1152          2675244  ...  The available data on the association between ...\n",
       "625           3168891  ...  This article analyses the practice of what is ...\n",
       "600           7467670  ...  The high degree of interindividual variability...\n",
       "1065          3834353  ...  Using ethnicity of surname, nativity, resident...\n",
       "971           3068425  ...  Well school-age children (N = 73) who had expe...\n",
       "304           2637716  ...  This article is published as a tribute to Prof...\n",
       "932          28535751  ...  BACKGROUND: Modifiable health-related behaviou...\n",
       "798          21215767  ...  The sheep offers a unique mammalian model in w...\n",
       "419           2614331  ...  STUDY OBJECTIVE: The aim of the study was to i...\n",
       "\n",
       "[10 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(io.BytesIO(uploaded['df8010_train.tsv']), delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "# Report the number of sentences.\n",
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Display 10 random rows from the data.\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "Kf90pLBb_SMe",
    "outputId": "6f64fdcd-165f-43e6-e7b8-f7be6955a54b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>PURPOSE: Psychological and sociodemographic fa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>BACKGROUND: Rheumatic heart disease (RHD) is a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>INTRODUCTION: Health care professionals have a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>BACKGROUND: Differences in health care utiliza...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Mega-sporting event regeneration, as a specifi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label\n",
       "346   PURPOSE: Psychological and sociodemographic fa...      0\n",
       "370   BACKGROUND: Rheumatic heart disease (RHD) is a...      0\n",
       "215   INTRODUCTION: Health care professionals have a...      0\n",
       "1049  BACKGROUND: Differences in health care utiliza...      0\n",
       "456   Mega-sporting event regeneration, as a specifi...      0"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mk7LS-8hUxwS"
   },
   "outputs": [],
   "source": [
    "# Create sentence and label lists\n",
    "sentences = df.sentence.values\n",
    "\n",
    "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
    "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
    "labels = df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142,
     "referenced_widgets": [
      "1e7cb53842fc4baf99fa463bca47f484",
      "3d03a219243d4749bf76777d1eac5647",
      "630dfd68bab94047b64b0507b7965fed",
      "06d00ff9917c414c9b45389445f8c337",
      "c84147c5e4414651a0b6f76254ebc4d1",
      "fd0a71100c5940d0a0ab2e2cea29cf04",
      "5170a0f90eab4ad48749ea6e5b8383db",
      "efdd36c4cdbf42e993b4bfed9f3096ff"
     ]
    },
    "colab_type": "code",
    "id": "3v0hizTPUx0b",
    "outputId": "368b6f6c-e3d9-4e45-8774-45d7b508e724"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7cb53842fc4baf99fa463bca47f484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenize the first sentence:\n",
      "['[CLS]', 'whether', 'a', 'community', 'is', 'in', 'the', 'path', 'of', 'a', 'natural', 'disaster', ',', 'the', 'target', 'of', 'an', 'act', 'of', 'terror', ',', 'or', 'simply', 'st', '##ri', '##ving', 'to', 'meet', 'the', 'demands', 'of', 'increasingly', 'dense', 'urban', 'populations', ',', 'a', 'community', 'res', '##ili', '##ence', 'paradigm', 'can', 'help', 'communities', 'and', 'individuals', 'not', 'just', 'to', 'mit', '##igate', 'damage', 'and', 'heal', ',', 'but', 'to', 'thrive', '.', 'this', 'article', 'discusses', 'experiences', 'from', 'recent', ',', 'large', '-', 'scale', 'disasters', 'to', 'explore', 'how', 'community', 'res', '##ili', '##ence', 'might', 'serve', 'as', 'a', 'sustainable', 'paradigm', 'for', 'organizing', 'public', 'health', 'and', 'medical', 'prepared', '##ness', ',', 'response', ',', 'and', 'recovery', '.', 'by', 'strengthening', 'health', 'systems', ',', 'meeting', 'the', 'needs', 'of', 'vulnerable', 'populations', ',', 'and', 'promoting', 'organizational', 'competence', ',', 'social', 'connected', '##ness', ',', 'and', 'psychological', 'health', ',', 'community', 'res', '##ili', '##ence', 'encourages', 'actions', 'that', 'build', 'prepared', '##ness', ',', 'promote', 'strong', 'day', '-', 'to', '-', 'day', 'systems', ',', 'and', 'address', 'the', 'underlying', 'social', 'deter', '##mina', '##nts', 'of', 'health', '.', 'thus', ',', 'community', 'res', '##ili', '##ence', 'res', '##onate', '##s', 'with', 'a', 'wide', 'array', 'of', 'stakeholders', ',', 'particularly', 'those', 'whose', 'work', 'routinely', 'addresses', 'health', ',', 'wellness', ',', 'or', 'societal', 'well', '-', 'being', '.', '[SEP]']\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "print (\"Tokenize the first sentence:\")\n",
    "print (tokenized_texts[0])\n",
    "print(len(tokenized_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ALVfOtybUx4h"
   },
   "outputs": [],
   "source": [
    "# Set the maximum sequence length. \n",
    "MAX_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_rMpuwpUx87"
   },
   "outputs": [],
   "source": [
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vy2VK-86Ux_v"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mOcE-n5wUyDY"
   },
   "outputs": [],
   "source": [
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b8t33dXlUyGk"
   },
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qW4JdDVdVOzt"
   },
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for training\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=2020, test_size=0.1)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=2020, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iyiyDiD-TiOi"
   },
   "source": [
    "**Bert**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZsXWUCyJVO95"
   },
   "outputs": [],
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hhiRbh56VPBH"
   },
   "outputs": [],
   "source": [
    "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
    "batch_size = 32\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "sgDgkDJiryaW",
    "outputId": "1bc1503c-73cf-4828-94a1-11fce861d702"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "793b3d20d2f54b0299c8ef76bf9736ba",
      "21cadbf5d5bb47189cd24f850e39e313",
      "97a969f89f7046e4966392eef0e77ae3",
      "2b93b83642f649c9ad4494a1e0a9aac5",
      "36ea41db9f6c4f0095c0919104615af4",
      "49a902069c884d25b57957f66950d6ec",
      "8854317ed100497a8aa7eefa0f936051",
      "361b28395a0a48cfad6fc66a62bf1df6",
      "bcba3df83ca04973b04f9ed8a8703fd2",
      "aed552dd80ff497198ebafec09d88e47",
      "d74ee01bc7224d1a8088e152eb037b85",
      "fa9779c87f7d415cb9dc833ef9124eb4",
      "aad469dbdf054460a61cd71e5e02e9ec",
      "0219fe5d300b48d398649be4c04a57c0",
      "a9ad3491e8364d2cad84be30be55450f",
      "514bc947274a4a5bba484f8d26706753"
     ]
    },
    "colab_type": "code",
    "id": "_lAU3erTVPJc",
    "outputId": "e11755a4-81fa-4063-be3f-a5f63ce35beb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793b3d20d2f54b0299c8ef76bf9736ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcba3df83ca04973b04f9ed8a8703fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels= 2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vo7LpBSNVPMl"
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVuTQB4jVPQq"
   },
   "outputs": [],
   "source": [
    "# This variable contains all of the hyperparemeter information our training loop needs\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QQ4OjCDoVPT_"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MrLCvSsXVPYX"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TFerE07QVPbv"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786
    },
    "colab_type": "code",
    "id": "EyO_Da_qVPfF",
    "outputId": "761df9d6-ffbe-41e9-acc3-b46633016a94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.49\n",
      "  Training epcoh took: 0:00:14\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.91\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 0:00:14\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.14\n",
      "  Training epcoh took: 0:00:13\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.91\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epcoh took: 0:00:13\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "accuracy_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        # have provided the `labels`.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull the \n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "        accuracy = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have\n",
    "            # not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UnKSZmq3YLuM"
   },
   "source": [
    "**Training Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "Gj1XHF4OWlj6",
    "outputId": "71b9702c-396f-4548-e9a8-8075fd861f85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4891908856875756,\n",
       " 0.24043939240715084,\n",
       " 0.14449680706157403,\n",
       " 0.09445487976293354]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Do9xKdBGg2z6"
   },
   "outputs": [],
   "source": [
    "# accuracy_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h8PSGm0YhWCs"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# create a new function defining a style\n",
    "def set_style():\n",
    "    \n",
    "    # Set reasonable defaults for font size for figure that will go in a paper\n",
    "    sns.set_context(\"paper\")\n",
    "    \n",
    "    # Set the font to be serif, rather than sans\n",
    "    sns.set(font='serif')\n",
    "    \n",
    "    # Make the background white, and specify the\n",
    "    # specific font family\n",
    "    sns.set_style(\"white\", {\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Times\", \"Palatino\", \"serif\"]\n",
    "    })\n",
    "    \n",
    "# call the function    \n",
    "set_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "colab_type": "code",
    "id": "LzIN_TMZJPSH",
    "outputId": "19a34f77-4a28-4d0c-8b3f-fbaa91b572fc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGuCAYAAAD2yjJgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title('Training Loss\\n Bert (batch = 32)')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tS1BK-s2J3zR"
   },
   "source": [
    "**Holdout Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "colab_type": "code",
    "id": "2GfCmETDAb69",
    "outputId": "769642d1-7701-46f0-8d92-d462586623e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-8a5c8d07-7de4-4fcf-8a45-3f83d95d0b79\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-8a5c8d07-7de4-4fcf-8a45-3f83d95d0b79\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving df8010_dev.tsv to df8010_dev.tsv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "KtuQBIDAWlnE",
    "outputId": "08e7d93e-e72e-4cd0-c5a6-ca17f8a70642"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (783 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(io.BytesIO(uploaded['df8010_dev.tsv']), delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Create sentence and label lists\n",
    "sentences = df.sentence.values\n",
    "labels = df.label.values\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask) \n",
    "\n",
    "# Convert to tensors.\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "QSMUrXteWlqd",
    "outputId": "407cf6e1-a8c3-47a6-8364-a2fad4804306"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 400 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "CZM-s5PFWlvP",
    "outputId": "0fdaeee9-bd8b-4a6e-8038-c9c25f41e678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 202 of 400 (50.50%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "m5rik1UwWlyO",
    "outputId": "c01ab78a-102c-4bf3-c68c-485c548bcfc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Matthews Corr. Coef. for each batch...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "# Evaluate each test batch using Matthew's correlation coefficient\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "\n",
    "    # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
    "    # and one column for \"1\"). Pick the label with the highest value and turn this\n",
    "    # in to a list of 0s and 1s.\n",
    "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "\n",
    "    # Calculate and store the coef for this batch.  \n",
    "    matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "    matthews_set.append(matthews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "_-cpfuraWl3D",
    "outputId": "fabcfb48-2118-4973-ef56-f96f2fe1ec66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8704453441295547,\n",
       " 0.7559289460184544,\n",
       " 0.875,\n",
       " 1.0,\n",
       " 0.8819171036881969,\n",
       " 0.8096598849105344,\n",
       " 0.938872452190116,\n",
       " 0.8749672939989046,\n",
       " 0.9393364366277243,\n",
       " 0.938872452190116,\n",
       " 0.9393364366277243,\n",
       " 0.875,\n",
       " 1.0]"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "QzXH9hlSWl6L",
    "outputId": "3b65a59a-e730-4132-e529-362fadf83175"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.896\n"
     ]
    }
   ],
   "source": [
    "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "# Calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('MCC: %.3f' % mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBnqPd4bKkh3"
   },
   "source": [
    "Note that we used [Matthews Correlation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html) to meausure this. It ranges from -1 to 1, with +1 being the best."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "UnKSZmq3YLuM",
    "vpZLQ2jBZNrM"
   ],
   "name": "Neural Network Classification (80's vs 10's)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0219fe5d300b48d398649be4c04a57c0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06d00ff9917c414c9b45389445f8c337": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efdd36c4cdbf42e993b4bfed9f3096ff",
      "placeholder": "​",
      "style": "IPY_MODEL_5170a0f90eab4ad48749ea6e5b8383db",
      "value": " 232k/232k [00:00&lt;00:00, 416kB/s]"
     }
    },
    "1e7cb53842fc4baf99fa463bca47f484": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_630dfd68bab94047b64b0507b7965fed",
       "IPY_MODEL_06d00ff9917c414c9b45389445f8c337"
      ],
      "layout": "IPY_MODEL_3d03a219243d4749bf76777d1eac5647"
     }
    },
    "21cadbf5d5bb47189cd24f850e39e313": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b93b83642f649c9ad4494a1e0a9aac5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_361b28395a0a48cfad6fc66a62bf1df6",
      "placeholder": "​",
      "style": "IPY_MODEL_8854317ed100497a8aa7eefa0f936051",
      "value": " 361/361 [00:41&lt;00:00, 8.74B/s]"
     }
    },
    "361b28395a0a48cfad6fc66a62bf1df6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36ea41db9f6c4f0095c0919104615af4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3d03a219243d4749bf76777d1eac5647": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49a902069c884d25b57957f66950d6ec": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "514bc947274a4a5bba484f8d26706753": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5170a0f90eab4ad48749ea6e5b8383db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "630dfd68bab94047b64b0507b7965fed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd0a71100c5940d0a0ab2e2cea29cf04",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c84147c5e4414651a0b6f76254ebc4d1",
      "value": 231508
     }
    },
    "793b3d20d2f54b0299c8ef76bf9736ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_97a969f89f7046e4966392eef0e77ae3",
       "IPY_MODEL_2b93b83642f649c9ad4494a1e0a9aac5"
      ],
      "layout": "IPY_MODEL_21cadbf5d5bb47189cd24f850e39e313"
     }
    },
    "8854317ed100497a8aa7eefa0f936051": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "97a969f89f7046e4966392eef0e77ae3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49a902069c884d25b57957f66950d6ec",
      "max": 361,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_36ea41db9f6c4f0095c0919104615af4",
      "value": 361
     }
    },
    "a9ad3491e8364d2cad84be30be55450f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aad469dbdf054460a61cd71e5e02e9ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "aed552dd80ff497198ebafec09d88e47": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bcba3df83ca04973b04f9ed8a8703fd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d74ee01bc7224d1a8088e152eb037b85",
       "IPY_MODEL_fa9779c87f7d415cb9dc833ef9124eb4"
      ],
      "layout": "IPY_MODEL_aed552dd80ff497198ebafec09d88e47"
     }
    },
    "c84147c5e4414651a0b6f76254ebc4d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d74ee01bc7224d1a8088e152eb037b85": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0219fe5d300b48d398649be4c04a57c0",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aad469dbdf054460a61cd71e5e02e9ec",
      "value": 440473133
     }
    },
    "efdd36c4cdbf42e993b4bfed9f3096ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa9779c87f7d415cb9dc833ef9124eb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_514bc947274a4a5bba484f8d26706753",
      "placeholder": "​",
      "style": "IPY_MODEL_a9ad3491e8364d2cad84be30be55450f",
      "value": " 440M/440M [00:39&lt;00:00, 11.1MB/s]"
     }
    },
    "fd0a71100c5940d0a0ab2e2cea29cf04": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
