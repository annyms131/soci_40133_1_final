{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qTcTRv0MOMFc"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 715
    },
    "colab_type": "code",
    "id": "J7ZjfEqkXhD1",
    "outputId": "23c1fa7c-f16b-4b62-dc2c-1db249a8f827"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/a0/32e3a4501ef480f7ea01aac329a716132f32f7911ef1c2fac228acc57ca7/transformers-2.6.0-py3-none-any.whl (540kB)\n",
      "\u001b[K     |████████████████████████████████| 542kB 8.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 19.8MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
      "\u001b[K     |████████████████████████████████| 870kB 50.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.27)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting tokenizers==0.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7MB 54.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.27 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.27)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->transformers) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->transformers) (0.15.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=3ee5ec8a7903474e250abd176df99a9552384abde43f37dcf8159a18afde324a\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
      "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.6.0\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nm8tlyvnPV9K",
    "outputId": "9d46d872-0f50-413f-c5db-76203fe1b25a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import AdamW, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KjVyxxH7Pqhc"
   },
   "source": [
    "*pre-processing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "C6UhXDEnT9op",
    "outputId": "1eccdfac-30ee-432a-f801-45d705378ee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "1T2tjRpzUaQV",
    "outputId": "d8c1f947-c23f-4d4f-8e06-3aab0bec6fc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ajkZyhJ9UjQw"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import AdamW, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "Enk-1K-FUl0y",
    "outputId": "f59aab18-70d5-4269-e74b-33bbf823d366"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=1b949901e6c59d78fe954aafd955670de5c407bf041261c3539b43684d7278d3\n",
      "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "Jq9fb34l04Fn",
    "outputId": "d8be760c-3b3b-49a5-ff2c-abfe1202c9bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "colab_type": "code",
    "id": "Duh-dCnSUqA7",
    "outputId": "a50a0b9f-8465-459b-df3d-7679f550b435"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-2a87899b-94c5-4596-a509-60c3df0f02d9\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-2a87899b-94c5-4596-a509-60c3df0f02d9\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving df7080_train.tsv to df7080_train.tsv\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "import os\n",
    "\n",
    "# The URL for the dataset zip file.\n",
    "#url = 'https://github.com/yjnkwn/Content-Analysis-2020/blob/master/week_8/data/hw8_train.tsv'\n",
    "\n",
    "# Download the file (if we haven't already)\n",
    "#if not os.path.exists('./hw8_train.tsv'):\n",
    "#    wget.download(url, './hw8_train.tsv')\n",
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k-zVruU6NfrR"
   },
   "source": [
    "Put your data into the format BERT expects.\n",
    "\n",
    "\n",
    "*   Column 1: An ID for the row (can be just a count, or even just the same number or letter for every row, if you don’t care to keep track of each individual example).\n",
    "\n",
    "*   Column 2: A label for the row as an int. These are the classification labels that your classifier aims to predict.\n",
    "\n",
    "*   Column 3: A column of all the same letter — this is a throw-away column that you need to include because the BERT model expects it.\n",
    "\n",
    "*   Column 4: The text examples you want to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "colab_type": "code",
    "id": "WSpm5fy_XZfr",
    "outputId": "4b6b528f-ec6b-4c53-af4b-c025504eb304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 154\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_source</th>\n",
       "      <th>label</th>\n",
       "      <th>label_notes</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>3169388</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>A prospective study was carried out on 133 neu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>7333334</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>This study was designed to obtain information ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3972951</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>Data on 776 survivors of the Massachusetts Hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1271211</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>Ranked eminence of creators and leaders was hy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>221759</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>A prospective design was used to study factors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>689592</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>In recent years the mental health field has be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1152751</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>Precise data on levels of prescribing of psych...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>670589</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>Normative data are presented for 570 children ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>939613</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>Determinants of occupational position in Polan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>963363</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>The author studied the significance of ethnic ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_source  ...                                           sentence\n",
       "138          3169388  ...  A prospective study was carried out on 133 neu...\n",
       "143          7333334  ...  This study was designed to obtain information ...\n",
       "56           3972951  ...  Data on 776 survivors of the Massachusetts Hea...\n",
       "86           1271211  ...  Ranked eminence of creators and leaders was hy...\n",
       "43            221759  ...  A prospective design was used to study factors...\n",
       "31            689592  ...  In recent years the mental health field has be...\n",
       "117          1152751  ...  Precise data on levels of prescribing of psych...\n",
       "45            670589  ...  Normative data are presented for 570 children ...\n",
       "11            939613  ...  Determinants of occupational position in Polan...\n",
       "2             963363  ...  The author studied the significance of ethnic ...\n",
       "\n",
       "[10 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(io.BytesIO(uploaded['df7080_train.tsv']), delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "# Report the number of sentences.\n",
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Display 10 random rows from the data.\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "Kf90pLBb_SMe",
    "outputId": "43899148-a56a-413e-aa81-072db8b5d3fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ludwik Fleck has shown in his discussion of th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Medication noncompliance is a significant prob...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Controversies are commonplace among scientists...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Although it is of both practical and theoretic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Preferences of weanling albino rats (15, 20, a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  label\n",
       "20   Ludwik Fleck has shown in his discussion of th...      0\n",
       "1    Medication noncompliance is a significant prob...      0\n",
       "23   Controversies are commonplace among scientists...      0\n",
       "113  Although it is of both practical and theoretic...      0\n",
       "115  Preferences of weanling albino rats (15, 20, a...      0"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mk7LS-8hUxwS"
   },
   "outputs": [],
   "source": [
    "# Create sentence and label lists\n",
    "sentences = df.sentence.values\n",
    "\n",
    "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
    "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
    "labels = df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142,
     "referenced_widgets": [
      "18b11ed1fbb7401a9798e50d1c8bd97b",
      "c1c67addde4f49b8b7caf332be738708",
      "9127e6cecd3244eba9899ec14659b355",
      "3d8100a68f1b4c2ca9e2da06f197ee66",
      "4025152f039348fb84258b041aba8f61",
      "b4941b3616bb4362a68bf66c3fa30265",
      "682acecd44884c3680dd935c5a8fa7ce",
      "0b17dd62f11f4868adbab6b03a248196"
     ]
    },
    "colab_type": "code",
    "id": "3v0hizTPUx0b",
    "outputId": "bf094a72-6e7f-445e-b045-b623b24e03e7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b11ed1fbb7401a9798e50d1c8bd97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenize the first sentence:\n",
      "['[CLS]', 'given', 'the', 'poor', 'quantity', 'and', 'quality', 'of', 'medical', 'care', 'in', 'most', 'villages', 'in', 'the', 'developing', 'countries', ',', 'the', 'economic', 'deter', '##mina', '##nts', 'of', 'village', 'health', 'are', 'the', 'supply', 'of', 'labour', ',', 'the', 'cash', 'flow', 'associated', 'with', 'that', 'labour', 'and', 'the', 'availability', 'of', 'land', '.', 'the', 'paper', 'examines', 'these', 'in', 'the', 'three', 'classical', \"'\", 'time', 'periods', \"'\", ',', 'arguing', 'that', 'inability', 'to', 'meet', 'labour', 'peaks', 'is', 'of', 'great', 'significance', 'in', 'explaining', 'seasonal', 'shortage', 'of', 'food', 'and', 'chronic', 'shortage', 'of', 'cash', '.', 'it', 'also', 'explains', 'community', 'indifference', 'to', 'up', '##kee', '##p', 'of', 'social', 'overhead', 'capital', '.', 'substitution', 'of', 'capital', 'goods', 'for', 'labour', 'is', 'socially', 'differentiated', ',', 'not', 'least', 'by', 'labour', 'availability', ',', 'and', 'leads', 'inevitably', 'to', 'a', 'reg', '##ress', '##ive', 'distribution', 'of', 'land', 'and', 'the', 'creation', 'or', 'en', '##lar', '##gement', 'of', 'a', 'class', 'of', 'land', '##less', 'labourers', '.', 'under', 'certain', 'limited', 'conditions', 'this', 'class', 'may', 'enjoy', 'a', 'rising', 'real', 'income', 'with', 'associated', 'health', '-', 'promo', '##tive', 'expenditures', '.', 'the', 'more', 'normal', 'case', ',', 'however', ',', 'is', 'extreme', 'poverty', ',', 'whether', 'rural', 'or', 'urban', ',', 'with', 'all', 'that', 'that', 'implies', 'for', 'the', 'under', '##mini', '##ng', 'of', 'health', '.', 'land', 'reform', 'therefore', 'becomes', 'a', 'necessary', 'pre', '##con', '##dition', 'of', 'health', 'promotion', '.', '[SEP]']\n",
      "154\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "print (\"Tokenize the first sentence:\")\n",
    "print (tokenized_texts[0])\n",
    "print(len(tokenized_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ALVfOtybUx4h"
   },
   "outputs": [],
   "source": [
    "# Set the maximum sequence length. \n",
    "MAX_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_rMpuwpUx87"
   },
   "outputs": [],
   "source": [
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vy2VK-86Ux_v"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mOcE-n5wUyDY"
   },
   "outputs": [],
   "source": [
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b8t33dXlUyGk"
   },
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qW4JdDVdVOzt"
   },
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for training\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=2020, test_size=0.1)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=2020, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iyiyDiD-TiOi"
   },
   "source": [
    "**Bert**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZsXWUCyJVO95"
   },
   "outputs": [],
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hhiRbh56VPBH"
   },
   "outputs": [],
   "source": [
    "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
    "batch_size = 32\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "sgDgkDJiryaW",
    "outputId": "1bc1503c-73cf-4828-94a1-11fce861d702"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "fd6716c44bdb452282f026b1b2eeb52e",
      "557e0221c025442abe00faa314a5d574",
      "9c6ae56d31404561bc165f01ac12f0d1",
      "d4a7bf9578d442a7b6f316fddbb21015",
      "15a33924893e4ba69d23981b6a1372be",
      "b51b58394c5246e7a0a2d2d0f35e73bd",
      "58dd3024a011490ba93c3b7bf49cf449",
      "1c3d27cf2ea54c42bb7e19b78db18620",
      "9c454a65bb8c41baab1b2079fdcd4160",
      "7668392464ac4f8aa76120d0c4c2b8e9",
      "43ff4ceb9538420bbb2f474f6b154484",
      "3186c0433b26472b94fa57fafc546d85",
      "62c458a1df3d46cab0d971a1ea619294",
      "c76c18f6d0aa4c2998635e18476fb889",
      "9300277039314696bc3cd5c147048cea",
      "5e4cad875ebd46b29c69334a901fb1ed"
     ]
    },
    "colab_type": "code",
    "id": "_lAU3erTVPJc",
    "outputId": "a7067b2e-bd9f-43f8-dd11-2704db9addf0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6716c44bdb452282f026b1b2eeb52e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c454a65bb8c41baab1b2079fdcd4160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels= 2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vo7LpBSNVPMl"
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVuTQB4jVPQq"
   },
   "outputs": [],
   "source": [
    "# This variable contains all of the hyperparemeter information our training loop needs\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QQ4OjCDoVPT_"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MrLCvSsXVPYX"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TFerE07QVPbv"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786
    },
    "colab_type": "code",
    "id": "EyO_Da_qVPfF",
    "outputId": "de8f6d31-1a57-4db7-81cc-685a3c75c157"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.50\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.70\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.31\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.72\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.31\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.68\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.31\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "accuracy_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        # have provided the `labels`.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull the \n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "        accuracy = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have\n",
    "            # not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UnKSZmq3YLuM"
   },
   "source": [
    "**Training Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "Gj1XHF4OWlj6",
    "outputId": "33896342-dc93-4265-bf0e-8931f8d904f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6876054763793945,\n",
       " 0.7006492018699646,\n",
       " 0.7150791406631469,\n",
       " 0.6817611217498779]"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Do9xKdBGg2z6"
   },
   "outputs": [],
   "source": [
    "# accuracy_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h8PSGm0YhWCs"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# create a new function defining a style\n",
    "def set_style():\n",
    "    \n",
    "    # Set reasonable defaults for font size for figure that will go in a paper\n",
    "    sns.set_context(\"paper\")\n",
    "    \n",
    "    # Set the font to be serif, rather than sans\n",
    "    sns.set(font='serif')\n",
    "    \n",
    "    # Make the background white, and specify the\n",
    "    # specific font family\n",
    "    sns.set_style(\"white\", {\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Times\", \"Palatino\", \"serif\"]\n",
    "    })\n",
    "    \n",
    "# call the function    \n",
    "set_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "colab_type": "code",
    "id": "LzIN_TMZJPSH",
    "outputId": "ba788f84-3c5c-400b-b7e7-6cf2049b4ce2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvoAAAGuCAYAAADh6KKpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\no8UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title('Training Loss\\n Bert (batch = 32)')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tS1BK-s2J3zR"
   },
   "source": [
    "**Holdout Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "colab_type": "code",
    "id": "2GfCmETDAb69",
    "outputId": "89385d53-7b50-4b02-e51b-e6549122b63b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-0f9808c5-474c-436f-aaf7-c8be4d05a2dd\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-0f9808c5-474c-436f-aaf7-c8be4d05a2dd\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving df7080_dev.tsv to df7080_dev.tsv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "KtuQBIDAWlnE",
    "outputId": "5bff8e6d-b587-4e94-9aa8-f04dd1725119"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(io.BytesIO(uploaded['df7080_dev.tsv']), delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Create sentence and label lists\n",
    "sentences = df.sentence.values\n",
    "labels = df.label.values\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask) \n",
    "\n",
    "# Convert to tensors.\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "QSMUrXteWlqd",
    "outputId": "c6f88c57-721e-4cdd-c970-f2a27ed4a492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 52 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "CZM-s5PFWlvP",
    "outputId": "0a5ae9b6-e280-4aa9-800a-f3dbeda049aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 30 of 52 (57.69%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "m5rik1UwWlyO",
    "outputId": "caff349f-da6d-49ef-b9b1-916c1a519fd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Matthews Corr. Coef. for each batch...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "# Evaluate each test batch using Matthew's correlation coefficient\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "\n",
    "    # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
    "    # and one column for \"1\"). Pick the label with the highest value and turn this\n",
    "    # in to a list of 0s and 1s.\n",
    "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "\n",
    "    # Calculate and store the coef for this batch.  \n",
    "    matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "    matthews_set.append(matthews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_-cpfuraWl3D",
    "outputId": "321e50fd-40f3-406f-f4f5-1063b28cb24a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.21713222235566895, 0.30151134457776363]"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "QzXH9hlSWl6L",
    "outputId": "ed6a7a82-35e3-4711-93f6-76dd710366d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.170\n"
     ]
    }
   ],
   "source": [
    "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "# Calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('MCC: %.3f' % mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBnqPd4bKkh3"
   },
   "source": [
    "Note that we used [Matthews Correlation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html) to meausure this. It ranges from -1 to 1, with +1 being the best."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "UnKSZmq3YLuM",
    "vpZLQ2jBZNrM"
   ],
   "name": "Neural Network Classification: 70's vs 80's",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b17dd62f11f4868adbab6b03a248196": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15a33924893e4ba69d23981b6a1372be": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "18b11ed1fbb7401a9798e50d1c8bd97b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9127e6cecd3244eba9899ec14659b355",
       "IPY_MODEL_3d8100a68f1b4c2ca9e2da06f197ee66"
      ],
      "layout": "IPY_MODEL_c1c67addde4f49b8b7caf332be738708"
     }
    },
    "1c3d27cf2ea54c42bb7e19b78db18620": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3186c0433b26472b94fa57fafc546d85": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e4cad875ebd46b29c69334a901fb1ed",
      "placeholder": "​",
      "style": "IPY_MODEL_9300277039314696bc3cd5c147048cea",
      "value": " 440M/440M [00:15&lt;00:00, 28.7MB/s]"
     }
    },
    "3d8100a68f1b4c2ca9e2da06f197ee66": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b17dd62f11f4868adbab6b03a248196",
      "placeholder": "​",
      "style": "IPY_MODEL_682acecd44884c3680dd935c5a8fa7ce",
      "value": " 232k/232k [00:00&lt;00:00, 805kB/s]"
     }
    },
    "4025152f039348fb84258b041aba8f61": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "43ff4ceb9538420bbb2f474f6b154484": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c76c18f6d0aa4c2998635e18476fb889",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_62c458a1df3d46cab0d971a1ea619294",
      "value": 440473133
     }
    },
    "557e0221c025442abe00faa314a5d574": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58dd3024a011490ba93c3b7bf49cf449": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e4cad875ebd46b29c69334a901fb1ed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62c458a1df3d46cab0d971a1ea619294": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "682acecd44884c3680dd935c5a8fa7ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7668392464ac4f8aa76120d0c4c2b8e9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9127e6cecd3244eba9899ec14659b355": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4941b3616bb4362a68bf66c3fa30265",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4025152f039348fb84258b041aba8f61",
      "value": 231508
     }
    },
    "9300277039314696bc3cd5c147048cea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9c454a65bb8c41baab1b2079fdcd4160": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_43ff4ceb9538420bbb2f474f6b154484",
       "IPY_MODEL_3186c0433b26472b94fa57fafc546d85"
      ],
      "layout": "IPY_MODEL_7668392464ac4f8aa76120d0c4c2b8e9"
     }
    },
    "9c6ae56d31404561bc165f01ac12f0d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b51b58394c5246e7a0a2d2d0f35e73bd",
      "max": 361,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_15a33924893e4ba69d23981b6a1372be",
      "value": 361
     }
    },
    "b4941b3616bb4362a68bf66c3fa30265": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b51b58394c5246e7a0a2d2d0f35e73bd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1c67addde4f49b8b7caf332be738708": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c76c18f6d0aa4c2998635e18476fb889": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4a7bf9578d442a7b6f316fddbb21015": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c3d27cf2ea54c42bb7e19b78db18620",
      "placeholder": "​",
      "style": "IPY_MODEL_58dd3024a011490ba93c3b7bf49cf449",
      "value": " 361/361 [00:00&lt;00:00, 9.34kB/s]"
     }
    },
    "fd6716c44bdb452282f026b1b2eeb52e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9c6ae56d31404561bc165f01ac12f0d1",
       "IPY_MODEL_d4a7bf9578d442a7b6f316fddbb21015"
      ],
      "layout": "IPY_MODEL_557e0221c025442abe00faa314a5d574"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
